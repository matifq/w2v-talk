{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 49.1MB 16kB/s  eta 0:00:01 0% |▎                               | 399kB 2.4MB/s eta 0:00:20    1% |▍                               | 552kB 3.2MB/s eta 0:00:16    3% |█                               | 1.7MB 6.1MB/s eta 0:00:08    15% |████▉                           | 7.4MB 8.6MB/s eta 0:00:05    44% |██████████████                  | 21.6MB 14.2MB/s eta 0:00:02    56% |██████████████████              | 27.5MB 4.2MB/s eta 0:00:06    60% |███████████████████▍            | 29.8MB 7.1MB/s eta 0:00:03    70% |██████████████████████▌         | 34.4MB 9.9MB/s eta 0:00:02    73% |███████████████████████▍        | 35.9MB 7.8MB/s eta 0:00:02�▊     | 41.0MB 16.3MB/s eta 0:00:01    86% |███████████████████████████▋    | 42.4MB 9.3MB/s eta 0:00:01    90% |████████████████████████████▉   | 44.3MB 10.5MB/s eta 0:00:01    96% |██████████████████████████████▉ | 47.2MB 14.9MB/s eta 0:00:01    98% |███████████████████████████████▌| 48.4MB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/ea/664c589ec41b9e9ac6e20cc1fe9016f3913332d0dc5498a5d7771e2835af/grpcio-1.12.1-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.0MB 59kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting numpy>=1.13.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 66kB/s eta 0:00:011   30% |█████████▋                      | 3.7MB 8.1MB/s eta 0:00:02    92% |█████████████████████████████▌  | 11.2MB 6.1MB/s eta 0:00:01    95% |██████████████████████████████▍ | 11.6MB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/8d/6664518f9b6ced0aa41cf50b989740909261d4c212557400c48e5cda0804/absl-py-0.2.2.tar.gz (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 5.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 285kB/s ta 0:00:011   21% |███████                         | 675kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 4.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 676kB/s eta 0:00:01    55% |█████████████████▊              | 491kB 10.3MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py, gast, termcolor, html5lib\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/a0/f8/e9/1933dbb3447ea6ef57062fd5461cb118deb8c2ed074e8344bf\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built absl-py gast termcolor html5lib\n",
      "Installing collected packages: grpcio, numpy, absl-py, gast, markdown, werkzeug, html5lib, bleach, tensorboard, termcolor, astor, tensorflow\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: html5lib 0.999999999\n",
      "    Uninstalling html5lib-0.999999999:\n",
      "      Successfully uninstalled html5lib-0.999999999\n",
      "  Found existing installation: bleach 2.0.0\n",
      "    Uninstalling bleach-2.0.0:\n",
      "      Successfully uninstalled bleach-2.0.0\n",
      "Successfully installed absl-py-0.2.2 astor-0.6.2 bleach-1.5.0 gast-0.2.0 grpcio-1.12.1 html5lib-0.9999999 markdown-2.6.11 numpy-1.14.5 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0 werkzeug-0.14.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 22.6MB 40kB/s  eta 0:00:01 2% |▊                               | 481kB 5.4MB/s eta 0:00:05    16% |█████▏                          | 3.7MB 10.0MB/s eta 0:00:02    17% |█████▊                          | 4.0MB 9.7MB/s eta 0:00:02    69% |██████████████████████▏         | 15.6MB 4.8MB/s eta 0:00:02    72% |███████████████████████▎        | 16.4MB 7.0MB/s eta 0:00:01    80% |█████████████████████████▋      | 18.1MB 8.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim)\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 302kB/s ta 0:00:011    96% |███████████████████████████████ | 1.3MB 611kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/1c/898ab9025a1725d15c3b121f6c91642a2535acc5d363acb328d6b37ff6d1/boto3-1.7.40-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.11.0,>=1.10.40 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/6f/e9c3981f8b7e93bfa4461b754563b0e917968947920d0bdcf2a7dcf77da2/botocore-1.10.40-py2.py3-none-any.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 208kB/s eta 0:00:01    31% |██████████▎                     | 1.4MB 5.5MB/s eta 0:00:01    87% |████████████████████████████    | 3.8MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.40->boto3->smart-open>=1.2.1->gensim)\n",
      "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.40->boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    99% |████████████████████████████████| 542kB 9.0MB/s eta 0:00:011    100% |████████████████████████████████| 552kB 1.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.48.0 boto3-1.7.40 botocore-1.10.40 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/files/11/11-0.txt\n",
      "180224/173595 [===============================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "path=get_file('alice.txt', origin='http://www.gutenberg.org/files/11/11-0.txt')\n",
    "corpus = open(path).readlines()[:300]\n",
    "corpus = [sentence for sentence in corpus if sentence.count(' ') >= 2]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "dim = 100\n",
    "window_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels   = []            \n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            \n",
    "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word)\n",
    "\n",
    "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
    "cbow.add(Dense(V, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x7f7b1eee9518>,\n",
       " <keras.layers.core.Lambda at 0x7f7b603a3e80>,\n",
       " <keras.layers.core.Dense at 0x7f7b1eed1be0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[348, 349, 65, 115, 10, 116, 57, 196, 197],\n",
       " [22, 117, 66, 17, 1, 67, 8, 350, 351, 29, 38, 352, 4, 27],\n",
       " [146, 38, 353, 354, 16, 355, 356, 5, 198, 5, 147, 32],\n",
       " [357, 67, 5, 118, 1, 358, 8, 1, 199, 148, 359, 360],\n",
       " [27, 22, 117, 32, 361, 29, 362, 148, 363]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "0 17412.565080165863\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "1 16152.256516456604\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "2 16024.155794858932\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "3 15933.206165194511\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "4 15825.334559202194\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "5 15722.699430406094\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "6 15632.660010188818\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "7 15551.537272304296\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "8 15473.687465369701\n",
      "  0 [[  0   0 349  65]] (1, 765)\n",
      "  1 [[  0 348  65 115]] (1, 765)\n",
      "  2 [[348 349 115  10]] (1, 765)\n",
      "  3 [[349  65  10 116]] (1, 765)\n",
      "2786\n",
      "9 15396.47467084229\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for i, (x, y) in enumerate(generate_data(corpus, window_size, V)):\n",
    "        if i<4:\n",
    "            print(' ', i, x, y.shape)\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "    print(i)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('vectors-cbow.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(V-1, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cbow.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    str_vec = ' '.join(map(str, list(vectors[i, :])))\n",
    "    f.write('{} {}\\n'.format(word, str_vec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors-cbow.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0.6486455202102661),\n",
       " ('one', 0.6459208130836487),\n",
       " ('this', 0.5973585844039917),\n",
       " ('adventures', 0.5596011281013489),\n",
       " ('alice’s', 0.5594749450683594),\n",
       " ('any', 0.5505132675170898),\n",
       " ('those', 0.5317860245704651),\n",
       " ('miles', 0.527005136013031),\n",
       " ('help', 0.5243159532546997),\n",
       " ('no', 0.5233829021453857)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 0.610198974609375),\n",
       " ('you', 0.6003904342651367),\n",
       " ('poor', 0.5682430863380432),\n",
       " ('them', 0.5612325668334961),\n",
       " ('that', 0.5536919832229614),\n",
       " ('eat', 0.5531008839607239),\n",
       " ('now', 0.5518883466720581),\n",
       " ('dark', 0.5485798120498657),\n",
       " ('marked', 0.548270046710968),\n",
       " ('thought', 0.5456354022026062)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['alice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
