{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pydot\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 646kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.6/site-packages (from pydot)\n",
      "Building wheels for collected packages: pydot\n",
      "  Running setup.py bdist_wheel for pydot ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
      "Successfully built pydot\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.2.4\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('alice.txt', origin=\"http://www.gutenberg.org/cache/epub/11/pg11.txt\")\n",
    "corpus = open(path).readlines()[0:200]\n",
    "\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "dim = 100\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            s = index-window_size\n",
    "            e = index+window_size+1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            for i in range(s, e):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word] )\n",
    "                    labels.append(words[i])\n",
    "\n",
    "            x = np.array(in_words,dtype=np.int32)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = Sequential()\n",
    "skipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram.add(Reshape((dim, )))\n",
    "skipgram.add(Dense(input_dim=dim, units=V, activation='softmax'))\n",
    "# SVG(model_to_dot(skipgram, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x7fdada22a358>,\n",
       " <keras.layers.core.Reshape at 0x7fdada275048>,\n",
       " <keras.layers.core.Dense at 0x7fdada275160>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "0 11489.388918876648\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "1 10761.77791762352\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "2 10547.217913866043\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "3 10571.68703341484\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "4 10600.938851118088\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "5 10587.000823497772\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "6 10563.15277004242\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "7 10537.503711938858\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "8 10507.644553780556\n",
      "  0 (2, 1) (2, 755)\n",
      "  1 (3, 1) (3, 755)\n",
      "  2 (4, 1) (4, 755)\n",
      "  3 (4, 1) (4, 755)\n",
      "9 10476.657511413097\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for i, (x, y) in enumerate(generate_data(corpus, window_size, V)):\n",
    "        if i<4:\n",
    "            print(' ', i, x.shape, y.shape)\n",
    "        loss += skipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('vectors-sg.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(V-1, dim))\n",
    "vectors = skipgram.get_weights()[0]\n",
    "for num, (word, i) in enumerate(tokenizer.word_index.items()):\n",
    "#     if num> 38:\n",
    "#         continue\n",
    "    str_vec = ' '.join(map(str, list(vectors[i, :])))\n",
    "    f.write('{} {}\\n'.format(word.strip(), str_vec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors-sg.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 0.47049450874328613),\n",
       " ('what', 0.4238196313381195),\n",
       " ('got', 0.40675997734069824),\n",
       " ('had', 0.4031747281551361),\n",
       " ('about', 0.3843131363391876),\n",
       " ('no', 0.3503741919994354),\n",
       " ('not', 0.3490760028362274),\n",
       " ('poor', 0.3486499786376953),\n",
       " ('how', 0.34808725118637085),\n",
       " ('right', 0.3421412706375122)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['alice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
